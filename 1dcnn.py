# -*- coding: utf-8 -*-
"""1DCNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PBSXw_2pPDIoaAoCla80zeJeRluhFyRS
"""

import pandas as pd
import numpy as np
import sklearn
import tensorflow

# Loading dataset


from google.colab import drive
import pandas as pd

# Mount Google Drive

drive.mount('/content/drive')


FILE_PATH = '/content/drive/MyDrive/gallstone_data.csv'




df = pd.read_csv(FILE_PATH)

# Clean the data
df = df.dropna(how='all')  # Remove completely empty rows
df = df.dropna(axis=1, how='all')  # Remove completely empty columns
df.columns = [str(col).strip() for col in df.columns]  # Clean column names



print(f"Shape: {df.shape[0]} rows × {df.shape[1]} columns")
print(f"\n Columns:")
print(df.columns.tolist())
print(f"\n First 5 rows:")
print(df.head())
print(f"\n Data types:")
print(df.dtypes)

# GALLSTONE ML ANALYSIS - COMPLETE PIPELINE


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import (confusion_matrix, accuracy_score, precision_score,
                             recall_score, f1_score, roc_curve, roc_auc_score)
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv1D, Flatten, Dropout
import warnings

print(f"\nDataset Shape: {df.shape}")
print(f"Target Variable: Gallstone Status")
print(f"  - 0: Gallstone Present")
print(f"  - 1: No Gallstone")

# DATA PREPROCESSING

print("\n Preprocessing data...")

# Separate features and target
X = df.drop('Gallstone Status', axis=1)
y = df['Gallstone Status']

print(f"  - Features: {X.shape[1]} columns")
print(f"  - Samples: {X.shape[0]} rows")
print(f"  - Class distribution:")
print(y.value_counts())

# First split: Train+Val vs Test (75% vs 25%)
X_trainval, X_test, y_trainval, y_test = train_test_split(
    X, y, test_size=0.25, random_state=42, stratify=y
)

# Second split: Train vs Val (80% vs 20% of trainval)
X_train, X_val, y_train, y_val = train_test_split(
    X_trainval, y_trainval, test_size=0.2, random_state=42, stratify=y_trainval
)

print(f"  - Training: {X_train.shape[0]} samples")
print(f"  - Validation: {X_val.shape[0]} samples")
print(f"  - Testing: {X_test.shape[0]} samples")

# NORMALIZATION

print("\n Applying Normalization...")

# Z-Score
scaler_zscore = StandardScaler()
X_train_zscore = scaler_zscore.fit_transform(X_train)
X_test_zscore = scaler_zscore.transform(X_test)

# Min-Max
scaler_minmax = MinMaxScaler()
X_train_minmax = scaler_minmax.fit_transform(X_train)
X_test_minmax = scaler_minmax.transform(X_test)

print("  ✓ Z-Score normalization applied")
print("  ✓ Min-Max normalization applied")

# INITIALIZE STORAGE

results = {
    'Model': [], 'Normalization': [], 'Accuracy': [],
    'Precision': [], 'Recall': [], 'F1-Score': [], 'ROC-AUC': []
}
confusion_matrices = {}
roc_curves = {}

# TRAIN MODELS - MIN-MAX


print(" MIN-MAX NORMALIZATION MODELS")

# 1D CNN
print("\n4️  1D CNN...")
X_train_cnn = X_train_minmax.reshape(X_train_minmax.shape[0], X_train_minmax.shape[1], 1)
X_test_cnn = X_test_minmax.reshape(X_test_minmax.shape[0], X_test_minmax.shape[1], 1)

cnn = Sequential([
    Conv1D(64, 3, activation='relu', input_shape=(X_train_minmax.shape[1], 1)),
    Conv1D(32, 3, activation='relu'),
    Flatten(),
    Dense(64, activation='relu'),
    Dropout(0.3),
    Dense(32, activation='relu'),
    Dense(1, activation='sigmoid')
])
cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
cnn.fit(X_train_cnn, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=0)

y_proba = cnn.predict(X_test_cnn, verbose=0).ravel()
y_pred = (y_proba > 0.5).astype(int)

results['Model'].append('1D CNN')
results['Normalization'].append('Min-Max')
results['Accuracy'].append(accuracy_score(y_test, y_pred))
results['Precision'].append(precision_score(y_test, y_pred))
results['Recall'].append(recall_score(y_test, y_pred))
results['F1-Score'].append(f1_score(y_test, y_pred))
results['ROC-AUC'].append(roc_auc_score(y_test, y_proba))
confusion_matrices['1D CNN (Min-Max)'] = confusion_matrix(y_test, y_pred)
fpr, tpr, _ = roc_curve(y_test, y_proba)
roc_curves['1D CNN'] = (fpr, tpr, results['ROC-AUC'][-1])
print(f"   Accuracy: {results['Accuracy'][-1]:.4f}")

!pip install keras-tuner

# CORRECT CNN HYPERPARAMETER TUNING


import tensorflow as tf
import keras_tuner as kt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, Dense, Dropout, Flatten
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split

# STEP 1: PROPER DATA SPLITTING

print(" Splitting data")

# First split: Train+Val vs Test (75% vs 25%)
X_trainval, X_test, y_trainval, y_test = train_test_split(
    X, y, test_size=0.25, random_state=42, stratify=y
)

# Second split: Train vs Val (80% vs 20% of trainval)
X_train, X_val, y_train, y_val = train_test_split(
    X_trainval, y_trainval, test_size=0.2, random_state=42, stratify=y_trainval
)

print(f"  - Training: {X_train.shape[0]} samples")
print(f"  - Validation: {X_val.shape[0]} samples")
print(f"  - Testing: {X_test.shape[0]} samples ")

# STEP 2: NORMALIZE DATA

print("\n Normalizing data")

scaler_minmax = MinMaxScaler()
X_train_norm = scaler_minmax.fit_transform(X_train)
X_val_norm = scaler_minmax.transform(X_val)
X_test_norm = scaler_minmax.transform(X_test)

# Reshape for CNN
X_train_cnn = X_train_norm.reshape(X_train_norm.shape[0], X_train_norm.shape[1], 1)
X_val_cnn = X_val_norm.reshape(X_val_norm.shape[0], X_val_norm.shape[1], 1)
X_test_cnn = X_test_norm.reshape(X_test_norm.shape[0], X_test_norm.shape[1], 1)

print(" Data normalized and reshaped")

# STEP 3: BUILD MODEL FUNCTION

def build_model(hp):
    model = Sequential()

    # First Conv layer
    model.add(Conv1D(
        filters=hp.Int('conv1_filters', min_value=32, max_value=128, step=32),
        kernel_size=hp.Choice('conv1_kernel', values=[2, 3, 5]),
        activation='relu',
        input_shape=(X_train_norm.shape[1], 1)
    ))

    # Second Conv layer
    model.add(Conv1D(
        filters=hp.Int('conv2_filters', min_value=16, max_value=64, step=16),
        kernel_size=hp.Choice('conv2_kernel', values=[2, 3, 5]),
        activation='relu'
    ))

    model.add(Flatten())

    # Dense layers
    model.add(Dense(
        units=hp.Int('dense1_units', min_value=32, max_value=128, step=32),
        activation='relu'
    ))
    model.add(Dropout(hp.Float('dropout', min_value=0.2, max_value=0.5, step=0.1)))

    model.add(Dense(
        units=hp.Int('dense2_units', min_value=16, max_value=64, step=16),
        activation='relu'
    ))

    model.add(Dense(1, activation='sigmoid'))

    # Optimizer
    lr = hp.Choice('learning_rate', values=[1e-4, 5e-4, 1e-3, 5e-3])
    optimizer = Adam(learning_rate=lr)

    model.compile(
        optimizer=optimizer,
        loss='binary_crossentropy',
        metrics=['accuracy']
    )

    return model

# STEP 4: HYPERPARAMETER TUNING

print("\n Starting hyperparameter tuning")


tuner = kt.Hyperband(
    build_model,
    objective='val_accuracy',
    max_epochs=50,
    factor=3,
    directory='cnn_tuning',
    project_name='gallstone_cnn_corrected',
    overwrite=True
)

# Early stopping to prevent overfitting
stop_early = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss',
    patience=5,
    restore_best_weights=True
)


tuner.search(
    X_train_cnn, y_train,
    epochs=50,
    batch_size=32,
    validation_data=(X_val_cnn, y_val),
    callbacks=[stop_early],
    verbose=1
)

# STEP 5: BEST HYPERPARAMETERS

best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]


print( "BEST HYPERPARAMETERS ")

print(f"Conv1 Filters: {best_hps.get('conv1_filters')}")
print(f"Conv1 Kernel: {best_hps.get('conv1_kernel')}")
print(f"Conv2 Filters: {best_hps.get('conv2_filters')}")
print(f"Conv2 Kernel: {best_hps.get('conv2_kernel')}")
print(f"Dense1 Units: {best_hps.get('dense1_units')}")
print(f"Dense2 Units: {best_hps.get('dense2_units')}")
print(f"Dropout: {best_hps.get('dropout')}")
print(f"Learning Rate: {best_hps.get('learning_rate')}")

# STEP 6: TRAIN FINAL MODEL

print("\n Training final model with best hyperparameters...")

# Combine train + val for final training
X_trainval_norm = scaler_minmax.fit_transform(X_trainval)
X_trainval_cnn = X_trainval_norm.reshape(X_trainval_norm.shape[0], X_trainval_norm.shape[1], 1)

final_model = tuner.hypermodel.build(best_hps)
history = final_model.fit(
    X_trainval_cnn, y_trainval,
    epochs=50,
    batch_size=32,
    validation_split=0.2,  # 20% of trainval for monitoring
    callbacks=[stop_early],
    verbose=1
)

# STEP 7: FINAL EVALUATION


test_loss, test_acc = final_model.evaluate(X_test_cnn, y_test, verbose=0)
y_pred_proba = final_model.predict(X_test_cnn, verbose=0).ravel()
y_pred = (y_pred_proba > 0.5).astype(int)

from sklearn.metrics import classification_report, confusion_matrix

print(f"\n Test Accuracy: {test_acc*100:.2f}%")
print(f"Test Loss: {test_loss:.4f}")

print("\n Classification Report:")
print(classification_report(y_test, y_pred, target_names=['Gallstone', 'No Gallstone']))

print("\n Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

# STEP 8: SAVE MODEL

final_model.save('best_gallstone_cnn_model.h5')
print("\n Model saved as 'best_gallstone_cnn_model.h5'")

import numpy as np
import pandas as pd
from sklearn.preprocessing import RobustScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, Dense, Dropout, Flatten, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import StratifiedKFold
import tensorflow as tf

# STEP 1: FEATURE ENGINEERING

print("\n  Creating engineered features")

def add_clinical_features(X_df):
    """Add clinically meaningful derived features"""
    X_new = X_df.copy()

    # 1. BMI Risk Category (Obesity is gallstone risk factor)
    if 'Body Mass Index (BMI)' in X_new.columns:
        X_new['BMI_Risk'] = (X_new['Body Mass Index (BMI)'] > 25).astype(float)

    # 2. Vitamin D Deficiency (< 20 ng/mL)
    if 'Vitamin D' in X_new.columns:
        X_new['VitD_Deficient'] = (X_new['Vitamin D'] < 20).astype(float)

    # 3. High Inflammation (CRP > 3 mg/L)
    if 'C-Reactive Protein (CRP)' in X_new.columns:
        X_new['High_CRP'] = (X_new['C-Reactive Protein (CRP)'] > 3).astype(float)

    # 4. Fat to Lean Mass Ratio
    if 'Total Body Fat Ratio (TBFR) (%)' in X_new.columns and 'Lean Mass (LM) (%)' in X_new.columns:
        X_new['Fat_Lean_Ratio'] = X_new['Total Body Fat Ratio (TBFR) (%)'] / (X_new['Lean Mass (LM) (%)'] + 0.001)

    # 5. Total Cholesterol / HDL Ratio (cardiovascular risk)
    if 'Total Cholesterol (TC)' in X_new.columns and 'High Density Lipoprotein (HDL)' in X_new.columns:
        X_new['TC_HDL_Ratio'] = X_new['Total Cholesterol (TC)'] / (X_new['High Density Lipoprotein (HDL)'] + 0.001)

    # 6. AST/ALT Ratio (liver health)
    if 'Aspartat Aminotransferaz (AST)' in X_new.columns and 'Alanin Aminotransferaz (ALT)' in X_new.columns:
        X_new['AST_ALT_Ratio'] = X_new['Aspartat Aminotransferaz (AST)'] / (X_new['Alanin Aminotransferaz (ALT)'] + 0.001)

    return X_new

# Apply feature engineering to original data
X_enhanced = add_clinical_features(X)

print(f"  Original features: {X.shape[1]}")
print(f"  Enhanced features: {X_enhanced.shape[1]}")
print(f"  Added {X_enhanced.shape[1] - X.shape[1]} new features")

# Re-split with enhanced features
X_trainval_enh, X_test_enh, y_trainval_enh, y_test_enh = train_test_split(
    X_enhanced, y, test_size=0.25, random_state=42, stratify=y
)
X_train_enh, X_val_enh, y_train_enh, y_val_enh = train_test_split(
    X_trainval_enh, y_trainval_enh, test_size=0.2, random_state=42, stratify=y_trainval_enh
)

# STEP 2: IMPROVED ARCHITECTURE

print("\n Building improved CNN architecture")

def build_improved_cnn(input_dim):
    """Improved CNN with BatchNormalization"""
    model = Sequential([
        # Conv Block 1
        Conv1D(64, 3, activation='relu', input_shape=(input_dim, 1)),
        BatchNormalization(),
        Conv1D(64, 3, activation='relu'),
        BatchNormalization(),
        Dropout(0.3),

        # Conv Block 2
        Conv1D(128, 3, activation='relu'),
        BatchNormalization(),
        Dropout(0.3),

        # Dense layers
        Flatten(),
        Dense(128, activation='relu'),
        BatchNormalization(),
        Dropout(0.4),
        Dense(64, activation='relu'),
        Dropout(0.3),
        Dense(1, activation='sigmoid')
    ])
    return model

# STEP 3: ENSEMBLE TRAINING (5 MODELS)

print("\nTraining ensemble of 5 models")

# Normalize data
scaler = RobustScaler()
X_train_scaled = scaler.fit_transform(X_train_enh)
X_val_scaled = scaler.transform(X_val_enh)
X_test_scaled = scaler.transform(X_test_enh)

# Reshape for CNN
X_train_cnn_enh = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)
X_val_cnn_enh = X_val_scaled.reshape(X_val_scaled.shape[0], X_val_scaled.shape[1], 1)
X_test_cnn_enh = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)

# Train ensemble
n_models = 5
ensemble_models = []
ensemble_val_scores = []

for i in range(n_models):
    print(f"\n  Training model {i+1}/{n_models}...")

    # Set different seed for diversity
    tf.random.set_seed(42 + i)
    np.random.seed(42 + i)

    # Build model
    model = build_improved_cnn(X_train_scaled.shape[1])
    model.compile(
        optimizer=Adam(learning_rate=0.001),
        loss='binary_crossentropy',
        metrics=['accuracy']
    )

    # Callbacks
    callbacks = [
        EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=0),
        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=0)
    ]

    # Train
    history = model.fit(
        X_train_cnn_enh, y_train_enh,
        epochs=100,
        batch_size=16,
        validation_data=(X_val_cnn_enh, y_val_enh),
        callbacks=callbacks,
        verbose=0
    )

    # Evaluate on validation
    val_loss, val_acc = model.evaluate(X_val_cnn_enh, y_val_enh, verbose=0)
    ensemble_val_scores.append(val_acc)
    ensemble_models.append(model)

    print(f"    Val Accuracy: {val_acc*100:.2f}%")

print(f"\n   Ensemble trained successfully")
print(f"  Mean validation accuracy: {np.mean(ensemble_val_scores)*100:.2f}% ± {np.std(ensemble_val_scores)*100:.2f}%")

# STEP 4: ENSEMBLE PREDICTIONS

print("\n Making ensemble predictions")

# Get predictions from all models
ensemble_predictions = []
for i, model in enumerate(ensemble_models):
    preds = model.predict(X_test_cnn_enh, verbose=0).ravel()
    ensemble_predictions.append(preds)

# Average predictions
ensemble_avg_preds = np.mean(ensemble_predictions, axis=0)
ensemble_final_preds = (ensemble_avg_preds > 0.5).astype(int)

# Calculate accuracy
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

ensemble_accuracy = accuracy_score(y_test_enh, ensemble_final_preds)

print(f"\n Ensemble Test Accuracy: {ensemble_accuracy*100:.2f}%")

# STEP 5: STACKING

print("\n  Stacking CNN with Gradient Boosting")

# Train Gradient Boosting on same enhanced features
gb_model = GradientBoostingClassifier(
    n_estimators=100,
    learning_rate=0.1,
    max_depth=3,
    random_state=42
)
gb_model.fit(X_train_scaled, y_train_enh)

# Get predictions from both models
cnn_test_probs = ensemble_avg_preds  # From ensemble
gb_test_probs = gb_model.predict_proba(X_test_scaled)[:, 1]

# Simple averaging (you can also use weighted average)
stacked_probs = 0.6 * cnn_test_probs + 0.4 * gb_test_probs  # CNN weighted more
stacked_preds = (stacked_probs > 0.5).astype(int)

stacked_accuracy = accuracy_score(y_test_enh, stacked_preds)

print(f" Stacked Model Test Accuracy: {stacked_accuracy*100:.2f}%")

# STEP 6: K-FOLD CROSS-VALIDATION (MOST ROBUST)

print("\n K-Fold Cross-Validation Ensemble")

def kfold_cnn_ensemble(X_data, y_data, X_test_data, n_splits=5):
    """Train models on different folds"""
    kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)

    # Scale data
    scaler = RobustScaler()
    X_scaled = scaler.fit_transform(X_data)
    X_test_scaled = scaler.transform(X_test_data)

    X_scaled_cnn = X_scaled.reshape(X_scaled.shape[0], X_scaled.shape[1], 1)
    X_test_cnn = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)

    fold_predictions = []
    fold_scores = []

    for fold, (train_idx, val_idx) in enumerate(kfold.split(X_scaled, y_data), 1):
        print(f"\n  Training fold {fold}/{n_splits}...")

        X_train_fold = X_scaled_cnn[train_idx]
        X_val_fold = X_scaled_cnn[val_idx]
        y_train_fold = y_data.iloc[train_idx]
        y_val_fold = y_data.iloc[val_idx]

        # Build and train model
        model = build_improved_cnn(X_scaled.shape[1])
        model.compile(
            optimizer=Adam(learning_rate=0.001),
            loss='binary_crossentropy',
            metrics=['accuracy']
        )

        model.fit(
            X_train_fold, y_train_fold,
            epochs=100,
            batch_size=16,
            validation_data=(X_val_fold, y_val_fold),
            callbacks=[EarlyStopping(patience=10, restore_best_weights=True, verbose=0)],
            verbose=0
        )

        # Validate
        val_score = model.evaluate(X_val_fold, y_val_fold, verbose=0)[1]
        fold_scores.append(val_score)
        print(f"    Fold {fold} Val Accuracy: {val_score*100:.2f}%")

        # Predict on test
        fold_preds = model.predict(X_test_cnn, verbose=0).ravel()
        fold_predictions.append(fold_preds)

    # Average predictions across folds
    final_predictions = np.mean(fold_predictions, axis=0)

    return final_predictions, fold_scores

kfold_preds, cv_scores = kfold_cnn_ensemble(
    X_trainval_enh, y_trainval_enh, X_test_enh, n_splits=5
)

kfold_final_preds = (kfold_preds > 0.5).astype(int)
kfold_accuracy = accuracy_score(y_test_enh, kfold_final_preds)

print(f"\n K-Fold Ensemble Test Accuracy: {kfold_accuracy*100:.2f}%")
print(f"   Cross-validation: {np.mean(cv_scores)*100:.2f}% ± {np.std(cv_scores)*100:.2f}%")


# FINAL RESULTS COMPARISON


print("FINAL ACCURACY COMPARISON")


results = pd.DataFrame({
    'Method': [
        'Original CNN (baseline)',
        'Ensemble (5 models)',
        'Stacked (CNN + GB)',
        'K-Fold Ensemble (5 folds)'
    ],
    'Test Accuracy (%)': [
        85.00,
        ensemble_accuracy * 100,
        stacked_accuracy * 100,
        kfold_accuracy * 100
    ],
    'Notes': [
        'Single model, baseline',
        'Average of 5 CNNs',
        'CNN + Gradient Boosting',
        'Most robust method'
    ]
})

results = results.sort_values('Test Accuracy (%)', ascending=False)
print("\n" + results.to_string(index=False))

# Find best method
best_method = results.iloc[0]
best_accuracy = best_method['Test Accuracy (%)']

print(f"\n Best Method: {best_method['Method']}")
print(f"   Accuracy: {best_accuracy:.2f}%")

if best_accuracy > 85.0:
    improvement = best_accuracy - 85.0
    print(f"    Improvement: +{improvement:.2f}%")

else:
    print(f"   Still at 85% ")

# DETAILED METRICS FOR BEST MODEL



# Use the best performing model's predictions
if kfold_accuracy >= max(ensemble_accuracy, stacked_accuracy):
    best_preds = kfold_final_preds
    best_name = "K-Fold Ensemble"
elif stacked_accuracy >= ensemble_accuracy:
    best_preds = stacked_preds
    best_name = "Stacked Model"
else:
    best_preds = ensemble_final_preds
    best_name = "Ensemble"

print(f"\nUsing: {best_name}")
print("\nClassification Report:")
print(classification_report(y_test_enh, best_preds,
                          target_names=['Gallstone', 'No Gallstone']))

print("\nConfusion Matrix:")
cm = confusion_matrix(y_test_enh, best_preds)
print(cm)
print(f"\nTrue Negatives (Gallstone correctly identified): {cm[0,0]}")
print(f"False Positives (False alarms): {cm[0,1]}")
print(f"False Negatives (Missed gallstones): {cm[1,0]}")
print(f"True Positives (No gallstone correctly identified): {cm[1,1]}")

if best_name == "Ensemble":
    # Save the first model from ensemble (they're all similar)
    ensemble_models[0].save('best_enhanced_cnn_model.keras')
    print(" Saved: best_enhanced_cnn_model.keras")
    print("  Note: This is one model from the ensemble")
    print("  For predictions, use ensemble averaging for best results")

# Save results summary
results.to_csv('accuracy_comparison_results.csv', index=False)
print(" Saved: accuracy_comparison_results.csv")

# VALIDATION CHECK


print(" Test set was NOT used during hyperparameter tuning")
print("Separate validation set was used for tuning")
print("Final model trained on train+val data")
print(" Test set used ONLY for final evaluation")
print(" This is the CORRECT way to do hyperparameter tuning!")

from sklearn.model_selection import StratifiedKFold

# 5-fold cross-validation
kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
cv_scores = []

for train_idx, val_idx in kfold.split(X_trainval, y_trainval):
    X_train_fold = X_trainval_norm[train_idx]
    X_val_fold = X_trainval_norm[val_idx]
    # Train and evaluate...

print(f"Mean CV Accuracy: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}")

# ROC Curve
from sklearn.metrics import roc_curve, auc

fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f'CNN (AUC = {roc_auc:.3f})')
plt.plot([0, 1], [0, 1], 'k--', label='Random')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve - Gallstone Prediction')
plt.legend()
plt.savefig('roc_curve.png', dpi=300)
plt.show()

# SHAP & LIME INTERPRETABILITY ANALYSIS
# FOR GALLSTONE PREDICTION CNN




!pip install shap lime -q

import shap
import lime
import lime.lime_tabular
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_curve, auc

# STEP 1: PREPARE DATA FOR INTERPRETATION

# Get feature names
feature_names = X.columns.tolist()
print(f"  - Features: {len(feature_names)}")

# Create wrapper for CNN predictions (SHAP/LIME need 2D input)
def cnn_predict_wrapper(X_2d):
    """Wrapper to convert 2D input to 3D for CNN"""
    X_3d = X_2d.reshape(X_2d.shape[0], X_2d.shape[1], 1)
    return final_model.predict(X_3d, verbose=0).ravel()

# STEP 2: SHAP ANALYSIS



n_background = 100  # Background samples for SHAP
n_explain = 50

# Prepare background and test samples
background_samples = X_trainval_norm[:n_background]
test_samples = X_test_norm[:n_explain]

print(f"\n Computing SHAP values...")
print(f"  - Background samples: {n_background}")
print(f"  - Test samples to explain: {n_explain}")
print(f"  - This may take 3-5 minutes...")

# Create SHAP explainer
explainer = shap.KernelExplainer(cnn_predict_wrapper, background_samples)
shap_values = explainer.shap_values(test_samples)

print("  SHAP values computed")

# VISUALIZATION 1: SHAP Summary Plot


plt.figure(figsize=(12, 10))
shap.summary_plot(
    shap_values,
    test_samples,
    feature_names=feature_names,
    show=False,
    max_display=20
)
plt.title("SHAP Feature Importance for Gallstone Prediction",
          fontsize=14, fontweight='bold', pad=20)
plt.tight_layout()
plt.savefig('shap_summary_plot.png', dpi=300, bbox_inches='tight')
plt.show()

print("  Saved as 'shap_summary_plot.png'")

# VISUALIZATION 2: SHAP Bar Plot


# Calculate mean absolute SHAP values
shap_importance = np.abs(shap_values).mean(axis=0)
importance_df = pd.DataFrame({
    'Feature': feature_names,
    'SHAP Importance': shap_importance
}).sort_values('SHAP Importance', ascending=False)

# Plot top 15 features
plt.figure(figsize=(10, 8))
top_15 = importance_df.head(15)
colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(top_15)))
plt.barh(range(len(top_15)), top_15['SHAP Importance'], color=colors)
plt.yticks(range(len(top_15)), top_15['Feature'])
plt.xlabel('Mean |SHAP Value|', fontsize=12, fontweight='bold')
plt.ylabel('Feature', fontsize=12, fontweight='bold')
plt.title('Top 15 Most Important Features (SHAP)',
          fontsize=14, fontweight='bold')
plt.gca().invert_yaxis()
plt.grid(axis='x', alpha=0.3)
plt.tight_layout()
plt.savefig('shap_feature_importance.png', dpi=300, bbox_inches='tight')
plt.show()

print("  ✓ Saved as 'shap_feature_importance.png'")

# Print top 10 features
print("\n Top 10 Most Important Features (SHAP):")

for idx, row in importance_df.head(10).iterrows():
    print(f"  {idx+1:2d}. {row['Feature']:40s} {row['SHAP Importance']:.4f}")

# VISUALIZATION 3: SHAP Waterfall Plot

# Explain 3 different patients
sample_indices = [0, 10, 20]  # First, middle, last samples

for i, sample_idx in enumerate(sample_indices):
    plt.figure(figsize=(10, 8))

    prediction = cnn_predict_wrapper(test_samples[sample_idx:sample_idx+1])[0]
    actual = y_test.iloc[sample_idx]

    shap.waterfall_plot(
        shap.Explanation(
            values=shap_values[sample_idx],
            base_values=explainer.expected_value,
            data=test_samples[sample_idx],
            feature_names=feature_names
        ),
        max_display=15,
        show=False
    )

    plt.title(f"Patient #{sample_idx}: Predicted={prediction:.3f}, Actual={'No Gallstone' if actual else 'Gallstone'}",
              fontsize=14, fontweight='bold')
    plt.tight_layout()
    plt.savefig(f'shap_waterfall_patient_{sample_idx}.png', dpi=300, bbox_inches='tight')
    plt.show()

    print(f"  Saved 'shap_waterfall_patient_{sample_idx}.png'")

# STEP 3: LIME ANALYSIS


# Create LIME explainer
lime_explainer = lime.lime_tabular.LimeTabularExplainer(
    training_data=X_trainval_norm,
    feature_names=feature_names,
    class_names=['Gallstone', 'No Gallstone'],
    mode='classification',
    discretize_continuous=True
)

print("\n Creating LIME explanations for individual predictions")

# Explain the same patients as SHAP
for sample_idx in sample_indices:
    # Explain instance
    lime_exp = lime_explainer.explain_instance(
        data_row=test_samples[sample_idx],
        predict_fn=lambda x: np.column_stack([
            1 - cnn_predict_wrapper(x),  # Class 0 probability
            cnn_predict_wrapper(x)       # Class 1 probability
        ]),
        num_features=15
    )

    # Plot LIME explanation
    fig = lime_exp.as_pyplot_figure()
    prediction = cnn_predict_wrapper(test_samples[sample_idx:sample_idx+1])[0]
    actual = y_test.iloc[sample_idx]
    plt.suptitle(f"LIME: Patient #{sample_idx} - Predicted={prediction:.3f}, Actual={'No Gallstone' if actual else 'Gallstone'}",
                 fontsize=12, fontweight='bold', y=1.02)
    plt.tight_layout()
    plt.savefig(f'lime_explanation_patient_{sample_idx}.png', dpi=300, bbox_inches='tight')
    plt.show()

    print(f"  Saved 'lime_explanation_patient_{sample_idx}.png'")

    # Print LIME feature contributions
    if sample_idx == sample_indices[0]:  # Print details for first patient
        print(f"\n LIME Feature Contributions for Patient #{sample_idx}:")
        print("-" * 60)
        for feature, weight in lime_exp.as_list()[:10]:
            print(f"  {feature:50s} {weight:+.4f}")

# STEP 4: COMPARE WITH ORIGINAL STUDY

# Original study's top features (Esen et al., 2024)
original_top_features = [
    'Vitamin D',
    'C-Reactive Protein (CRP)',
    'Total Body Water (TBW)',
    'Lean Mass (LM) (%)'
]

print("\n Original Study (Gradient Boosting) Top Features:")
for i, feat in enumerate(original_top_features, 1):
    print(f"  {i}. {feat}")

print("\n Your CNN Model (SHAP) Top Features:")
cnn_top_features = importance_df.head(4)['Feature'].tolist()
for i, feat in enumerate(cnn_top_features, 1):
    print(f"  {i}. {feat}")

# Check overlap
overlap = set(original_top_features) & set(cnn_top_features)
overlap_count = len(overlap)

print(f"\n Overlapping features: {overlap_count}/{len(original_top_features)}")
if overlap:
    print(f"   Common features: {', '.join(overlap)}")
else:
    print(f"   ")

# VISUALIZATION 4: Comparison Plot


# Create comparison dataframe
comparison_data = []
for feat in feature_names:
    shap_rank = list(importance_df['Feature']).index(feat) + 1 if feat in importance_df['Feature'].values else None
    is_original = feat in original_top_features
    comparison_data.append({
        'Feature': feat,
        'SHAP_Rank': shap_rank,
        'SHAP_Importance': importance_df[importance_df['Feature'] == feat]['SHAP Importance'].values[0] if feat in importance_df['Feature'].values else 0,
        'In_Original_Top4': is_original
    })

comparison_df = pd.DataFrame(comparison_data).sort_values('SHAP_Importance', ascending=False).head(10)

# Plot
fig, ax = plt.subplots(figsize=(12, 6))
colors = ['#ff6b6b' if x else '#4ecdc4' for x in comparison_df['In_Original_Top4']]
bars = ax.barh(range(len(comparison_df)), comparison_df['SHAP_Importance'], color=colors)
ax.set_yticks(range(len(comparison_df)))
ax.set_yticklabels(comparison_df['Feature'])
ax.set_xlabel('SHAP Importance', fontsize=12, fontweight='bold')
ax.set_title('Top 10 Features: CNN vs Original Study', fontsize=14, fontweight='bold')
ax.invert_yaxis()
ax.grid(axis='x', alpha=0.3)

# Legend
from matplotlib.patches import Patch
legend_elements = [
    Patch(facecolor='#ff6b6b', label='Also in Original Study Top 4'),
    Patch(facecolor='#4ecdc4', label='CNN-specific Important Features')
]
ax.legend(handles=legend_elements, loc='lower right')

plt.tight_layout()
plt.savefig('feature_comparison_original_vs_cnn.png', dpi=300, bbox_inches='tight')
plt.show()

print(" Saved as 'feature_comparison_original_vs_cnn.png'")


# VISUALIZATION 5: ROC Curve

print("\n Creating ROC curve...")

fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='#2ecc71', linewidth=2.5,
         label=f'CNN (AUC = {roc_auc:.3f})')
plt.plot([0, 1], [0, 1], 'k--', linewidth=1.5, label='Random Classifier')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate', fontsize=12, fontweight='bold')
plt.ylabel('True Positive Rate', fontsize=12, fontweight='bold')
plt.title('ROC Curve - Gallstone Prediction', fontsize=14, fontweight='bold')
plt.legend(loc="lower right", fontsize=11)
plt.grid(alpha=0.3)
plt.tight_layout()
plt.savefig('roc_curve.png', dpi=300, bbox_inches='tight')
plt.show()

print("  Saved as 'roc_curve.png'")

# STEP 5: CREATE SUMMARY TABLE

# Create summary dataframe
summary_df = importance_df.head(20).copy()
summary_df['Rank'] = range(1, len(summary_df) + 1)
summary_df['In Original Top 4'] = summary_df['Feature'].isin(original_top_features)
summary_df = summary_df[['Rank', 'Feature', 'SHAP Importance', 'In Original Top 4']]

print("\n" + summary_df.to_string(index=False))

# Save summary
summary_df.to_csv('feature_importance_summary.csv', index=False)
print("\n Summary saved as 'feature_importance_summary.csv'")

# Analyze top features
top_5_features = importance_df.head(5)['Feature'].tolist()

print("\n Key Findings:")


# Check for body composition features
body_comp_keywords = ['Body', 'Fat', 'Lean', 'Mass', 'BMI', 'Weight', 'Obesity']
body_comp_count = sum(1 for feat in top_5_features if any(kw in feat for kw in body_comp_keywords))

# Check for lab values
lab_keywords = ['Vitamin', 'CRP', 'Cholesterol', 'Glucose', 'Triglyceride']
lab_count = sum(1 for feat in top_5_features if any(kw in feat for kw in lab_keywords))

print(f"\n  • Body composition features in top 5: {body_comp_count}/5")
print(f"  • Laboratory markers in top 5: {lab_count}/5")

if 'Vitamin D' in top_5_features or 'C-Reactive Protein (CRP)' in top_5_features:
    print(f"\n   Model validates known clinical risk factors:")
    if 'Vitamin D' in top_5_features:
        print(f"    - Vitamin D deficiency (known gallstone risk factor)")
    if 'C-Reactive Protein (CRP)' in top_5_features:
        print(f"    - Inflammation markers (CRP)")

print(f"\n  • Agreement with original study: {overlap_count}/4 features match")

